# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 1

## –ó–∞–¥–∞–Ω–∏–µ 1
![–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ](./images/lab01/01.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
![–í–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∏—Å–ª–∞](./images/lab01/02.png)

## –ó–∞–¥–∞–Ω–∏–µ 3 
![–¶–µ–Ω—ã](./images/lab01/03.png)

## –ó–∞–¥–∞–Ω–∏–µ 4
![–í—Ä–µ–º—è](./images/lab01/04.png)

## –ó–∞–¥–∞–Ω–∏–µ 5 
![–§–ò–û](./images/lab01/05.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 2

## –ó–∞–¥–∞–Ω–∏–µ 1

```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if not nums:
        return 'ValueError'
    return (min(nums), max(nums))
t = [3, -1, 5, 5, 0]
m = [42]
n = [-5, -2, -9]
b = []
a = [1.5, 2, 2.0, -3.1]
print(min_max(t))
print(min_max(m))
print(min_max(n))
print(min_max(b))
print(min_max(a))
```
![min_max](./images/lab02/1.1_arrays.png)

```python
def unique_sorted(nums: list[float | int]) -> list[float | int]:
    if not nums:
        return []
    return sorted(set(nums))
t = [3, 1, 2, 1, 3]
c = []
a = [-1, -1, 0, 2, 2]
b = [1.0, 1, 2.5, 2.5, 0]
print(unique_sorted(t))
print(unique_sorted(c))
print(unique_sorted(a))
print(unique_sorted(b))
```

![unique_sorted](./images/lab02/1.2_arrays.png)

```python
def flatten(mat: list[list | tuple]) -> list:
    res = []
    for r in mat:
        if not isinstance(r, (list, tuple)):
            return 'TypeError'
        res.extend(r)
    return res
t = [[1, 2], [3, 4]]
a = [[1, 2], (3, 4, 5)]
b = [[1], [], [2, 3]]
c = [[1, 2], "ab"]
print(flatten(t))
print(flatten(a))
print(flatten(b))
print(flatten(c))
```
![flatten](./images/lab02/1.3_arrays.png)

## –ó–∞–¥–∞–Ω–∏–µ 2

```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if not mat:
      return []
    
    row = len(mat[0])
    for row1 in mat:
        if len(row1) != row:
         return 'ValueError'
    return [[mat[q][w] for q in range(len(mat))] for w in range(row)]
t = [[1, 2, 3]]
a = [[1], [2], [3]]
b = [[1, 2], [3, 4]]
c = []
d = [[1, 2], [3]]
print(transpose(t))
print(transpose(a))
print(transpose(b))
print(transpose(c))
print(transpose(d))
```
![transpose](./images/lab02/2.1_matrix.png)

```python
def row_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat:
      return []
    
    row = len(mat[0])
    for row1 in mat:
        if len(row1) != row:
         return 'ValueError'
    return [sum(r) for r in mat]
t = [[1, 2, 3], [4, 5, 6]]
a = [[-1, 1], [10, -10]]
b = [[0, 0], [0, 0]]
c = [[1, 2], [3]]
print(row_sums(t))
print(row_sums(a))
print(row_sums(b))
print(row_sums(c))
```
![row_sums](./images/lab02/2.2_matrix.png)

```python
def col_sums(mat: list[list[float | int]]) -> list[float]:
    if not mat:
      return []
    
    row = len(mat[0])
    for row1 in mat:
        if len(row1) != row:
         return 'ValueError'
    return [sum(r) for r in zip(*mat)]
t = [[1, 2, 3], [4, 5, 6]]
a = [[-1, 1], [10, -10]]
b = [[0, 0], [0, 0]]
c = [[1, 2], [3]]
print(col_sums(t))
print(col_sums(a))
print(col_sums(b))
print(col_sums(c))
```
![col_sums](./images/lab02/2.3_matrix.png)

## –ó–∞–¥–∞–Ω–∏–µ 3

```python
def format_record(rec: tuple[str, str, float]) -> str:
    try:
        fio, gr, gpa = rec
        fio2 = ' '.join(fio.split()).split()
        fam = fio2[0]

        if (fio not in rec) or (gr not in rec) or (gpa not in rec):
            return 'ValueError'

        ini = []
        for i in range(1, len(fio2)):
            if i <= 2:
                ini.append(f"{fio2[i][0]}.")
        res = f"{fam} {''.join(ini)}, –≥—Ä. {gr}, GPA {gpa:.2f}"
        return res
    except:
       return 'ValueError'
t = ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)
a = ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)
b = ("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)
c = ("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)
d = (" ", "ABB-01")
print(format_record(t))
print(format_record(a))
print(format_record(b))
print(format_record(c))
print(format_record(d))
```

![–ó–∞–ø–∏—Å–∏](./images/lab02/typles.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 3

## –ó–∞–¥–∞–Ω–∏–µ 1

### Normalize

```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    if casefold:
        text = text.casefold()
    text = ' '.join(text.split())
    text = text.strip()
    return text
a = '–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t'
b = "—ë–∂–∏–∫, –Å–ª–∫–∞"
c = "Hello\r\nWorld"
d = "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
print(normalize(a))
print(normalize(b))
print(normalize(c))
print(normalize(d))
```
![normalize](./images/lab03/1.1_normalize.png)

### Tokenize

```python
import re

def tokenize(text: str) -> list[str]:
    t = r'[\w]+(?:-[\w]+)*'
    l = re.findall(t, text, re.UNICODE)
    return l

a = "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
b = "hello,world!!!"
c = "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"
d = "2025 –≥–æ–¥"
e = "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
print(tokenize(a))
print(tokenize(b))
print(tokenize(c))
print(tokenize(d))
print(tokenize(e))
```

![tokenize](./images/lab03/1.2_tokenize.png)

### Count_freq + top_n
```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    freq = {}
    for i in tokens:
        if i in freq:
            freq[i] += 1
        else:
            freq[i] = 1
    return freq

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    items = []
    for word in freq:
        count = freq[word]
        items.append((word, count))
    items.sort(key=lambda i: (-i[1], i[0]))
    return items[:n]


a = ["a","b","a","c","b","a"]
b = ["bb","aa","bb","aa","cc"]
print(count_freq(a))
print(count_freq(b))
print(top_n(count_freq(a)))
print(top_n(count_freq(b)))
```

![count_freq + top_n](./images/lab03/1.3-4_count_freq.png)

## –ó–∞–¥–∞–Ω–∏–µ 2

### –ó–∞–¥–∞–Ω–∏–µ B

```python
import sys
import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    if casefold:
        text = text.casefold()
    text = ' '.join(text.split())
    text = text.strip()
    return text

def tokenize(text: str) -> list[str]:
    t = r'[\w]+(?:-[\w]+)*'
    l = re.findall(t, text, re.UNICODE)
    return l

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq = {}
    for i in tokens:
        if i in freq:
            freq[i] += 1
        else:
            freq[i] = 1
    return freq

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    items = []
    for word in freq:
        count = freq[word]
        items.append((word, count))
    items.sort(key=lambda i: (-i[1], i[0]))
    return items[:n]

a =  "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"

nt = normalize(a)
allwords = tokenize(nt)
uw = count_freq(allwords)
top = top_n(uw, 5)

print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(allwords)}')
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(uw)}")
print("–¢–æ–ø-5:")
for y in top:
    print(y[0] + ': ' + str(y[1]))
```

![–ó–∞–¥–∞–Ω–∏–µ B.1](./images/lab03/2.1.1_text_stats.png)
![–ó–∞–¥–∞–Ω–∏–µ B.2](./images/lab03/2.1.2_text_stats.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 4

## –§—É–Ω–∫—Ü–∏–∏, —Ñ–∞–π–ª io_txt_csv.py: 
```python
from pathlib import Path
import csv
import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, –∑–∞–º–µ–Ω—è–µ—Ç —ë –Ω–∞ –µ, —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã"""
    if yo2e:
        text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    if casefold:
        text = text.casefold()
    text = ' '.join(text.split())
    text = text.strip()
    return text

def tokenize(text: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã (—Å–ª–æ–≤–∞)"""
    t = r'[\w]+(?:-[\w]+)*'
    l = re.findall(t, text, re.UNICODE)
    return l

def count_freq(tokens: list[str]) -> dict[str, int]:
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"""
    freq = {}
    for i in tokens:
        if i in freq:
            freq[i] += 1
        else:
            freq[i] = 1
    return freq

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
    items = []
    for word in freq:
        count = freq[word]
        items.append((word, count))
    items.sort(key=lambda i: (-i[1], i[0]))
    return items[:n]

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """–ß–∏—Ç–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞"""
    print(f"–ß–∏—Ç–∞—é —Ñ–∞–π–ª: {path}")
    p = Path(path)
    text = p.read_text(encoding=encoding)
    print(f"–ü—Ä–æ—á–∏—Ç–∞–ª {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    return text

def write_csv(rows: list[tuple | list], path: str | Path,
                header: tuple[str, ...] | None = None) -> None:
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª"""
    p = Path(path)

    if rows:
        first_length = len(rows[0])
        for i, row in enumerate(rows):
            if len(row) != first_length:
                raise ValueError(f"–æ—à–∏–±–∫–∞ –ª—é—Ç–∞—è")
            
    with p.open('w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)

        if header is not None:
            writer.writerow(header)

        for row in rows:
            writer.writerow(row)
```

## –ó–∞–¥–∞–Ω–∏–µ –ê
```python
from pathlib import Path
import sys

current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

from io_txt_csv import normalize, tokenize, count_freq, top_n, read_text, write_csv

def main():
    current_file = Path(__file__)
    print(f"–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: {current_file}")

    input_path = current_file.parent / 'data' / 'input.txt'
    output_path = current_file.parent / 'data' / 'output.csv'

    print(f"–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É: {input_path}")
    print(f"–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É: {output_path}")

    input_path.parent.mkdir(parents=True, exist_ok=True)
    input_path.write_text("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!", encoding='utf-8')
    print(f"–°–æ–∑–¥–∞–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω —Ñ–∞–π–ª: {input_path}")

    result = read_text(input_path)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —á—Ç–µ–Ω–∏—è: {result}")

    normalized_text = normalize(result)
    print(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {normalized_text}")

    tokens = tokenize(normalized_text)
    print(f"–¢–æ–∫–µ–Ω—ã: {tokens}")

    frequencies = count_freq(tokens)
    print(f"–ß–∞—Å—Ç–æ—Ç—ã: {frequencies}")

    word_counts = top_n(frequencies, n=len(frequencies))
    print(f"–ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤: {word_counts}")

    write_csv(word_counts, output_path, header=('word', 'count'))
    print(f"CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_path}")

if __name__ == "__main__":
    main()
```

## –ó–∞–¥–∞–Ω–∏–µ B 
```python
from pathlib import Path
from io_txt_csv import normalize, tokenize, count_freq, top_n, read_text, write_csv

current_file = Path(__file__)
input_path = current_file.parent.parent / "src/data/input_test.txt"
output_path = current_file.parent.parent / "src/data/output.csv"

print(f"–¢–µ–∫—É—â–∏–π —Ñ–∞–π–ª: {current_file}")
print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_path}")
print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")

input_path.parent.mkdir(parents=True, exist_ok=True)
if input_path.exists():
    input_path.unlink()
input_path.write_text("–ü—Ä–∏–≤–µ—Ç", encoding="utf-8")
print(f"–°–æ–∑–¥–∞–Ω –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: {input_path}")

text = read_text(input_path, "utf-8")
print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ: '{text}' ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")

normalized_text = normalize(text)
tokens = tokenize(normalized_text)
frequencies = count_freq(tokens)

print(f"–¢–æ–∫–µ–Ω—ã: {tokens}")
print(f"–ß–∞—Å—Ç–æ—Ç—ã: {frequencies}")

word_counts = top_n(frequencies, n=len(frequencies))
write_csv([[word, count] for word, count in word_counts], 
          output_path, header=('word', 'count'))
print(f"CSV —Å–æ–∑–¥–∞–Ω: {output_path}")

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {sum(frequencies.values())}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(frequencies)}")

print("–¢–æ–ø 5 —Å–ª–æ–≤:")
top_5 = top_n(frequencies, n=5)
for i, (word, count) in enumerate(top_5, 1):
    print(f"  {i}. '{word}': {count}") if top_5 else print("  –ù–µ—Ç —Å–ª–æ–≤")
```


## –¢–µ—Å—Ç –∫–µ–π—Å—ã –∫ –∑–∞–¥–∞–Ω–∏—é –ê:
![1](./images/lab04/1.png)
![2](./images/lab04/2.png)

## –¢–µ—Å—Ç –∫–µ–π—Å—ã –∫ –∑–∞–¥–∞–Ω–∏—é B
![3](./images/lab04/3.png)
![4](./images/lab04/4.png)
![5](./images/lab04/5.png)